\chapter{Background}
\label{chap:background}

Nowadays, the complexity of software systems is increasing. As we develop more and more functionality in safety oriented solutions, we can reach a complexity level, where formal verification isn't enough on it's own to assure a specified behavior. With the introduction of Internet of Things (\iot), and new mobile communication technologies, systems are becoming dynamic, and this transition needs new embedded monitoring solutions.

\section{Embedded systems}

Embedded systems are units with dedicated functionality. Often embedded systems consists of more specialized units, which are interconnected by some network e.g. the \textls{CAN} bus in an automobile. A typical car can have microcontrollers from a dozen to ten dozens \citep{VEHICLE_DYN}.

Most of todays' microprocessors can be found in embedded electronics. Embedded systems considered more restricted compared to personal computers. Memory and computation power is limited, and most of the cases these systems needs to be real--time.

Embedded systems often utilized in time critical solutions, where is simpler to delegate tasks to different processors compared to a shared, more powerful computer.

With the rising of \emph{Single Board Computers} (\textls{SBC}) like Raspberry Pi, BeagleBone, ODROID, anybody can easily access embeddable hardware platforms. With the trending of IoT technologies e.g. sensor networks, manufacturers are moving towards more open sourced, accessible platforms which everybody can use.

\section{Model driven software developement}

Using models to design complex systems is essential in traditional engineering disciplines. Models help us understand a complex problem and its potential solutions through abstraction. Therefore, it seems obvious that software systems, which are often among the most complex engineering systems, can benefit greatly from using models and modeling techniques. \citep{pastor2008model}

In safety--critical systems, model driven software development is mandatory. In these systems, e.g. requirement traceability is necessity. Without a model based software design process, the traceability of requirements and the development process of the components are hard to follow. In a traditional software development process, these documents would have been written by natural language on paper, or some electronically document format. Finding tracing information between documents in a complex system is almost impossible.

Model based software development consists two main components:
\begin{itemize}
	\item Tools: Tools allow the developers to create models, e.g. UML, EMF, SysML
	\item Process: The process describes how to use tools in a development process, e.g. SYSMOD, RUP, Y model
\end{itemize}

\begin{figure}[!h]
	\centering
	\begin{tikzpicture}[
		start chain=going below,
		squarednode/.style={
			rectangle,
			draw=black,
			very thick,
			minimum height=1.5cm,
			text width=2.5cm,
			inner sep=2mm,
			align=center
		},
		every loop/.style={
			looseness=2,
			text width=2cm
		}
		]
		\node[squarednode] (D1) {System\\Design Model};
		\node[squarednode] (D2) [below = of D1, xshift = .5cm] {Architecture\\Design Model};
		\node[squarednode] (D3) [below = of D2, xshift = .5cm] {Component\\Design Model};
		\node[squarednode] (V1) [right = 3cm of D1] {System\\V\&V Model};
		\node[squarednode] (V2) [below = of V1, xshift = -.5cm]{Architecture\\V\&V Model};
		\node[squarednode] (V3) [below = of V2, xshift = -.5cm] {Component\\V\&V Model};

		\node[squarednode] (GC) at ($(D3)!0.5!(V3)$) [yshift=-3.5cm, text width=5.5cm] {Design + V\&V Artifacts\\(Source code, Glue code,\\Config. Tables, Test Cases,\\Monitors, Fault Trees, etc.)};

		\draw[thick,->] (D3.south) -- (GC.north -| D3) node [midway, left, align=right] {Code generation};
		\draw[thick,->] (V3.south) -- (GC.north -| V3) node [midway, right, align=left] {Test generation};

		\draw[thick,->] (D1) edge [loop left, align=right] node {Design rules} ();
		\draw[thick,->] (D2) edge [loop left, align=right] node {Design rules} ();
		\draw[thick,->] (D3) edge [loop left, align=right] node {Design rules} ();

		\draw[thick,->] (V1) edge [loop right, align=left] node {Formal methods} ();
		\draw[thick,->] (V2) edge [loop right, align=left] node {Formal methods} ();
		\draw[thick,->] (V3) edge [loop right, align=left] node {Formal methods} ();

		\draw[thick,->] (D1.south) -- (D2.north) node [midway, left, align=right] {Refine};
		\draw[thick,->] (D2.south) -- (D3.north) node [midway, left, align=right] {Refine};
		\draw[thick,<-] (V1.south) -- (V2.north) node [midway, right, align=left] {Use};
		\draw[thick,<-] (V2.south) -- (V3.north) node [midway, right, align=left] {Use};

		\draw[thick,<->] (D1.east) -- (V1.west);
		\draw[thick,<->] (D2.east) -- (V2.west);
		\draw[thick,<->] (D3.east) -- (V3.west);

	\end{tikzpicture}
	\caption{Diagram of the Y model \citep{MDSD_INTRO}}
	\label{fig:y_model}
\end{figure}

\subsection{Y model}

The Y model (\cref{fig:y_model}) depicts a basic workflow of model based software development. Every design level has it's own design rules it must conform to. The detailed levels of the system must be traceable to the upper levels. The artifact of the design process is the generated code, and generated test cases.

\section{Verification techniques}

\subsection{Design time verification}

Design time verification, or formal verification is the analysis of a software in the design process. It's mostly based around model driven system development, where we specify the entire software\,---and hardware if needed---\,as a model. On this model, we can run analysis to ensure that software always behaves according to the specification. Formal verification is a commonly used process in the verification of safety critical systems, or networking protocols.

As mentioned, dynamic behavior takes significant part of a modern software system, even in a safety critical cases. As the availability of sensor networks and advanced communication technologies spreads, distributed components pose a challenge in the verification process.

While formally verifying a software, the software engineer builds a model, and tests this model against given scenarios, searching for incorrect behavior. But the engineer is the responsible for the specification of the scenarios, and not all corner cases are obvious. This method can lead situations, where the system may hide a potential hazard, but because no verification indicated incorrect behavior, we find the system verified.

\subsection{Runtime verification}

On behalf of design time verification which is performed while developing the software components, runtime verification checks the systems behavior while operating. This is beneficial because if an erroneous state in the software is not found at the formal verification stage of development, runtime verification techniques can still detect the faulty state of the software, and raise an error. This error can be detected by other components, and\,---if possible\,---resolve this error.

Runtime verification components can be implemented in form of monitors. The monitors' responsibility is to take signals from a software, and compare it to a simplified model inside of the monitor.

Software components can communicate with the monitor via multiple ways. The communication method implies where the monitor is placed.
\begin{enumerate}
	\item Directly by calling the monitors' methods. In this case the monitors' methods are called from the monitored process itself. The monitor is placed in the same compilation unit.
	      \item\label{item:agent} Remotely by an agent. An embedded agent component is called from the monitored components, or the agent is actively extracting the monitored softwares' state. The agent then forwards this information to the monitor. The monitor can be virtually everywhere.
\end{enumerate}

\section{Complex event processing}

Complex event processing (\cep) is a set of techniques and tools to help us understand and control event-driven information systems \citep{Luckham:2001:PEI:515781}.

Complex event processing frameworks exists because of the problem of processing large amount of events coming inside into an application. While its easy to search  very simple patterns inside an incoming on--line stream of information, e.g. the same thing happening $x$ times after each other, at the moment the developer wants to find more complex, maybe temporal pattern in this incoming information, this problems grows into a nontrivial one.

For example take an example from the financial world. A bank wants to avoid fraud with it's clients credit card. The bank receives a huge amount of payment information daily, and wants to filter
\begin{itemize}
	\item The same person's credit card
	\item With some temporal property e.g. in a day
	\item Used somewhere outside from the country the last 2 payments was done
\end{itemize}

With the capability to find such specific occasions, complex event processor is great for monitoring purposes. This thesis will show the usage of this monitoring capability with very limited resources.

The basic workflow for monitoring with \cep is illustrated in \cref{fig:cep_monitoring}. If the developement is model based, according to the Y-model, from the high level specification one can generate complex event processor patterns (\cref{subsec:cep_patterns}). After compilation, or interpretation of the patterns, the monitor can be executed by a \cep engine (\cref{subsec:cep_engine}). The generated monitor is then capable of signaling the violation of the high level specification.

\begin{figure}
	\centering
	\begin{tikzpicture}[
		start chain=going below,
		node distance=5mm,
		squarednodec/.style={
			squarednode,
			on chain,
			text width = 4cm,
			align = center
		},
		]
		\node[squarednodec] (A) {High level specification};
		\node[squarednodec] (B) {Pattern creation};
		\node[squarednodec] (C) {Generation of monitor};
		\node[squarednodec] (D) {Monitor execution};

		\draw[thick, ->] (A) -- (B);
		\draw[thick, ->] (B) -- (C);
		\draw[thick, ->] (C) -- (D);

	\end{tikzpicture}
	\caption{A \cep based monitoring solution}
	\label{fig:cep_monitoring}
\end{figure}

\subsection{Event}
\label{subsec:cep_event}

An event is an instance of an event type, which is distinguished by an unique name.
Event is the basic and most important aspect of a complex event processor. Events can be classified into two main categories:
\begin{itemize}
	\item Atomic event. These events marks a point in time, and cannot be broken down to other events.
	\item Complex event. A complex event can be caused by some pattern consisting atomic, and other complex events.
\end{itemize}

\needspace{10em}
\subsection{Event streams}
\label{subsec:cep_eventstream}
\label{subsection:event_streams}
The input of a \cep are streams of atomic events. These atomic events can come from various sources, as follows.
\begin{enumerate}
	\item Direct event stream handling. This is an imperative approach, because the events pushed programmatically from code through an API.

	\item Model change events. The application have an underlying model and framework, and it can notify the event processor in case of various changes (deletion, insertion, update) of the model.\label{item:model}

	\item Databases. This is a special case of \cref{item:model}, where the model is not implemented in the application, but stored in a database.
\end{enumerate}
\vspace{1ex}
If an \cep supports it, it is possible to mix input streams, and rules can interconnect these event sources.

\subsection{Patterns}
\label{subsec:cep_patterns}
Event processors provides formalisms to describe patterns.

The complex nature of the rules comes from the usage of the reference of other patterns. One pattern might depend on the activation of another pattern.

With this functionality, one can build hierarchical system of pattern. Instead of creating one big pattern\,---if its even possible---\,containing all the functionality, divided smaller, reusable patterns can be written.

\subsection{Engine}
\label{subsec:cep_engine}

A \cep is built around it's execution engine. The engine accepts the input stream(s), and output is the matches of the patterns. In monitoring situations the output of engine is the event of an erroneous state of the monitored process (\cref{fig:cep_monitoring_event_flow}).

\begin{figure}
	\centering
	\begin{tikzpicture}[
		start chain=going below,
		node distance = 3mm,
		squarednodec/.style={
			squarednode,
			on chain,
			align = center,
		}
		]
		\node[squarednodec] (A) {Direct stream};
		\node[squarednodec] (B) {Model change};
		\node[squarednodec] (C) {Database};
		\node[squarednodec, minimum height=2cm] (D) [right = 2cm of B] {CEP Engine};

		\draw[thick, ->] (A.east) -- (D);
		\draw[thick, ->] (B.east) -- (D);
		\draw[thick, ->] (C.east) -- (D);
		\draw[thick, ->] (D.east) -- ++(3,0) node [above, midway] {Error signals};

		\draw[thick, ->] (5,0.5) -- ++(2,0) node [pos = 1.5] {Event flow};

	\end{tikzpicture}
	\caption{Event flow in a \cep based monitor}
	\label{fig:cep_monitoring_event_flow}
\end{figure}

\subsection{Conclusion}

Traditionally complex event processors are complex frameworks like databases, and modeling frameworks. The aim of this thesis to generate small, but effective code, and run it on embedded environments, where it's impossible to run a full \cep software stack.

\section{Real-time systems}

Real-time systems have some temporal constraints (deadline), which the system must satisfy. In a real-time system the correctness of behavior not only depend on the control logic, but on the temporal properties of it. These constrains often focused on the response time of the system in case of events.

We can divide real-time systems into two main category: hard and soft real-time.

\subsubsection{Hard real-time}

Hard realtime systems have precisely defined deadlines which the system must suffice. If the system hit a deadline, it is considered a failure. An example of a hard-realtime system is an airbag controller inside a car. After a collision, there is a very narrow time band where the airbag must be deployed. A hard-realtime system must have some proof they can deterministically handle these situations without hitting a deadline.

\subsubsection{Soft real-time}

Soft real-time differ from hard-realtime system in the way they stay correct if they miss the deadline, but operation between time constraints needed for normal functionality. One example is the processing of mouse input. If the processing of mouse input lags, it can be annoying for the user. Nonetheless the functionality stays intact, but the usability seriously degrades.

\subsection{Realtime operating systems}

The type of an operating system is defined by how the scheduler decides which program to run and when. For example, the scheduler used in a multi user operating system (such as Unix) will ensure each user gets a fair amount of the processing time. As another example, the scheduler in a desktop operating system (such as Windows) will try and ensure the computer remains responsive to its user.

The scheduler in a \emph{Real Time Operating System} (\rtos) is designed to provide a predictable\,--normally described as deterministic--\,execution pattern. This is particularly of interest to embedded systems as embedded systems often have real time requirements. A real time requirements is one that specifies that the embedded system must respond to a certain event within a strictly defined time (the deadline). A guarantee to meet real time requirements can only be made if the behavior of the operating system's scheduler can be predicted (and is therefore deterministic).\citep{RTOS}

Most of the safety oriented systems based around realtime operating systems. It is important to understand realtime operating systems exists to provide determinism, and not additional performance. With these response guarantees, the software engineer can be sure the incoming interrupt will be served, and the software components responsible for the processing will get \cpu time between the guaranteed limits.

\section{Mission critical systems}

A mission critical system is which failure can cause severe financial loss, natural disaster, or loss of human lives. Most of the time mission critical systems utilizes hard-realtime systems. Association between mission critical systems, and hard-realtime is common, but there are counterexamples:

One example is a bank transaction software. A transaction execution software does not need to execute transactions in real-time, but if a transaction does not executed correctly, it can mean serious financial loss.

Another example is a printer head. A printer head is a hard real time component, because if it hits the specified deadline, the output will not be correct. A misprinted page from a desktop printer doesn't meet the definition of a mission critical system.

\section{Domain specific language}

A domain-specific language (\dsl) is a programming language or executable specification language that offers, through appropriate notations and abstractions, expressive power focused on, and usually restricted to, a particular problem domain \citep{van2000domain}.

\dsl{}s are useful, because the language's designer completely in control of the language, and the constraints. These constrains can help the designer get real-time feedback about the correctness of the code written in \dsl. For example an automaton definition \dsl can support design time checking states of an automaton, and provide feedback to the designer which states are unreachable.

\section{Eclipse}

Eclipse is an open integrated development environment (\textls{IDE}) actively developed since 2001. Eclipse is the main platform of modeling tools, e.g. \emf, \textls{AUTOSAR}, \textls{UML}, \textls{SysML}.

Eclipse achieve this modularity with it's radical usage of plug-ins. The entire \textls{IDE} is built around plug-ins. A representative example is the Eclipse \textls{IDE} this thesis was developed on, contains 1653 plug-ins itself.

To make such a distributed plug-in network usable, Eclipse utilizes the Open Services Gateway initiative (\textls{OSGi}) framework. The \textls{OSGi} framework uses the extra metadata bundled with Java packages to handle dependency requirements inside the runtime, and to interconnect the plug-ins with each other.

\subsection{Eclipse Modelign Framework}

The Eclipse Modelign Framework (\emf) is a well development modeling framework to support model creation for model driven development.

Many frameworks, like the \viatra framework. Such frameworks can use the notification support coming out of the box with \emf to support advanced incremential features.

\begin{itemize}
	\item Visual model editing. The \emf editor gives a tree based, or completely cal editing of it's models.
	\item Notification support for change events.
	\item Code generation features.
	      \begin{itemize}
	      	\item Model code generation. The framework can generate Java classes, which can be used from any Java application.
	      	\item Editor code generation. A generated editor as an Eclipse plugin, which gives the developer a basic tool to assemble an instance model.
	      \end{itemize}
\end{itemize}
